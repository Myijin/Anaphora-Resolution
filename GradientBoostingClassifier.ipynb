{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from feature import get_features\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import model_selection, multiclass, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4454, 11)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gh_test = pd.read_csv(\"gendered-pronoun-resolution/gap-test.tsv\", delimiter='\\t')\n",
    "gh_valid = pd.read_csv(\"gendered-pronoun-resolution/gap-validation.tsv\", delimiter='\\t')\n",
    "gh_devop = pd.read_csv(\"gendered-pronoun-resolution/gap-development-revised.tsv\", delimiter='\\t')\n",
    "train = pd.concat((gh_test, gh_valid, gh_devop)).rename(columns={'A': 'A_Noun', 'B': 'B_Noun'}).reset_index(drop=True)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = -0.18\n",
    "train = get_features(train, para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(df):\n",
    "    df = df.rename(columns={'A-coref':'A', 'B-coref':'B'})\n",
    "    df['A'] = df['A'].astype(int)\n",
    "    df['B'] = df['B'].astype(int)\n",
    "    df['NEITHER'] = 1.0 - (df['A'] + df['B'])\n",
    "    \n",
    "    def label_class(row):\n",
    "        if row['A']==1:\n",
    "            return 0\n",
    "        if row['B']==1:\n",
    "            return 1\n",
    "        if row['NEITHER']==1:\n",
    "            return 2\n",
    "        else:\n",
    "            print(row)\n",
    "        \n",
    "    df['class'] = df.apply(lambda row: label_class(row), axis = 1)\n",
    "    return df\n",
    "\n",
    "train = get_label(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.652473 using GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.01, loss='deviance', max_depth=5,\n",
      "              max_features='sqrt', max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=5, min_samples_split=8,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=800,\n",
      "              presort='auto', random_state=37, subsample=0.77, verbose=0,\n",
      "              warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = GradientBoostingClassifier(max_features='sqrt', learning_rate=0.01, \n",
    "                                   n_estimators=800, random_state=37)\n",
    "\n",
    "param_grid = dict(subsample=[0.77, 0.8], max_depth=[5, 6], \n",
    "                  min_samples_leaf=[4, 5],\n",
    "                  min_samples_split=[8, 9, 10])\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_log_loss', cv=5, n_jobs=-1)\n",
    "grid_result = grid.fit(train[col].fillna(0), train['class'])\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.653122 using GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.01, loss='deviance', max_depth=5,\n",
      "              max_features='sqrt', max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=4, min_samples_split=8,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=800,\n",
      "              presort='auto', random_state=51, subsample=0.77, verbose=0,\n",
      "              warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = GradientBoostingClassifier(max_features='sqrt', learning_rate=0.01, \n",
    "                                   max_depth=5, n_estimators=800, random_state=51)\n",
    "\n",
    "param_grid = dict(subsample=[0.77, 0.78, 0.8], \n",
    "                  min_samples_leaf=[4, 5],\n",
    "                  min_samples_split=[8, 9, 10])\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_log_loss', cv=5, n_jobs=-1)\n",
    "grid_result = grid.fit(train[col].fillna(0), train['class'])\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('log_loss', 0.6034104869463657)\n",
      "('accuracy', 0.7418630751964085)\n",
      "('log_loss', 0.6395317328603699)\n",
      "('accuracy', 0.7295173961840629)\n",
      "('log_loss', 0.6418225837766699)\n",
      "('accuracy', 0.7295173961840629)\n",
      "('log_loss', 0.6497989331254129)\n",
      "('accuracy', 0.7227833894500562)\n",
      "('log_loss', 0.6114020682185027)\n",
      "('accuracy', 0.7306397306397306)\n",
      "Average 0.629193160985\n",
      "Average 0.730864197531\n",
      "---\n",
      "\n",
      "('log_loss', 0.5988410109888181)\n",
      "('accuracy', 0.7418630751964085)\n",
      "('log_loss', 0.6412555030547529)\n",
      "('accuracy', 0.7239057239057239)\n",
      "('log_loss', 0.6417969534145618)\n",
      "('accuracy', 0.7261503928170595)\n",
      "('log_loss', 0.6431063332482446)\n",
      "('accuracy', 0.7317620650953984)\n",
      "('log_loss', 0.6084233848159613)\n",
      "('accuracy', 0.734006734006734)\n",
      "Average 0.626684637104\n",
      "Average 0.731537598204\n",
      "---\n",
      "\n",
      "('log_loss', 0.5985554346009012)\n",
      "('accuracy', 0.7396184062850729)\n",
      "('log_loss', 0.6418090975510642)\n",
      "('accuracy', 0.7250280583613917)\n",
      "('log_loss', 0.6422166232117205)\n",
      "('accuracy', 0.7317620650953984)\n",
      "('log_loss', 0.6443636210515464)\n",
      "('accuracy', 0.7272727272727273)\n",
      "('log_loss', 0.609506657757012)\n",
      "('accuracy', 0.7328843995510662)\n",
      "Average 0.627290286834\n",
      "Average 0.731313131313\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "col = ['pronoun_type', 'pred_A', 'after_A', 'pred_B', 'after_B', \n",
    "       'head_A', 'nsubj_A', 'dobj_A', 'pobj_A', 'poss_A', 'paral_A', 'ad_A', 'nonad_A', \n",
    "       'head_B', 'nsubj_B', 'dobj_B', 'pobj_B', 'poss_B', 'paral_B', 'ad_B', 'nonad_B', \n",
    "       'pos_sent_A', 'pos_sent_B', 'A-dist', 'B-dist']\n",
    "\n",
    "clf1 = GradientBoostingClassifier(subsample=0.77, max_features='sqrt', max_depth=5, \n",
    "                                  min_samples_leaf=5, min_samples_split=8, \n",
    "                                  learning_rate=0.01, n_estimators=800, random_state=20)\n",
    "\n",
    "clf2 = GradientBoostingClassifier(subsample=0.8, max_features='sqrt', max_depth=6, \n",
    "                                  min_samples_leaf=4, min_samples_split=10, \n",
    "                                  learning_rate=0.01, n_estimators=800, random_state=20)\n",
    "\n",
    "clf3 = GradientBoostingClassifier(subsample=0.8, max_features='sqrt', max_depth=6, \n",
    "                                  min_samples_leaf=4, min_samples_split=9, \n",
    "                                  learning_rate=0.01, n_estimators=800, random_state=20)\n",
    "dictc = {}\n",
    "for clf in [clf1, clf2, clf3]:\n",
    "    dictc[clf] = {}\n",
    "    dictc[clf][\"log_loss\"]=[]\n",
    "    dictc[clf][\"accuracy\"]=[]\n",
    "    for rstate in [1, 2, 3, 4, 5]:\n",
    "        x1, x2, y1, y2 = model_selection.train_test_split(train[col].fillna(0), train['class'], test_size=0.2, random_state=rstate)\n",
    "        clf.fit(x1, y1)\n",
    "        y_pred = clf.predict_proba(x2)\n",
    "\n",
    "        logloss = metrics.log_loss(y2, y_pred)\n",
    "        acc = clf.score(x2, y2)\n",
    "        print('log_loss', logloss)\n",
    "        print('accuracy', acc)\n",
    "        dictc[clf][\"log_loss\"].append(logloss)\n",
    "        dictc[clf][\"accuracy\"].append(acc)\n",
    "    \n",
    "    print(\"Average {}\".format(sum(dictc[clf][\"log_loss\"]) / float(5)))\n",
    "    print(\"Average {}\".format(sum(dictc[clf][\"accuracy\"]) / float(5)))\n",
    "    print('---\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

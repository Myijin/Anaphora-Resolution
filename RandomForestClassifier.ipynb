{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 9)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from sklearn import model_selection, multiclass, metrics, ensemble\n",
    "from feature import get_features\n",
    "\n",
    "test = pd.read_csv('gendered-pronoun-resolution/test_stage_1.tsv', delimiter='\\t').rename(columns={'A': 'A_Noun', 'B': 'B_Noun'})\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4454, 11)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gh_test = pd.read_csv(\"gendered-pronoun-resolution/gap-test.tsv\", delimiter='\\t')\n",
    "gh_valid = pd.read_csv(\"gendered-pronoun-resolution/gap-validation.tsv\", delimiter='\\t')\n",
    "gh_devop = pd.read_csv(\"gendered-pronoun-resolution/gap-development-revised.tsv\", delimiter='\\t')\n",
    "train = pd.concat((gh_test, gh_valid, gh_devop)).rename(columns={'A': 'A_Noun', 'B': 'B_Noun'}).reset_index(drop=True)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = -0.18\n",
    "train = get_features(train, para)\n",
    "test = get_features(test, para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(df):\n",
    "    df = df.rename(columns={'A-coref':'A', 'B-coref':'B'})\n",
    "    df['A'] = df['A'].astype(int)\n",
    "    df['B'] = df['B'].astype(int)\n",
    "    df['NEITHER'] = 1.0 - (df['A'] + df['B'])\n",
    "    \n",
    "    def label_class(row):\n",
    "        if row['A']==1:\n",
    "            return 0\n",
    "        if row['B']==1:\n",
    "            return 1\n",
    "        if row['NEITHER']==1:\n",
    "            return 2\n",
    "        else:\n",
    "            print(row)\n",
    "        \n",
    "    df['class'] = df.apply(lambda row: label_class(row), axis = 1)\n",
    "    return df\n",
    "\n",
    "train = get_label(train)\n",
    "gh_devop = gh_devop.rename(columns={'A': 'A_Noun', 'B': 'B_Noun'})\n",
    "submition = get_label(gh_devop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "col = ['pronoun_type', 'pred_A', 'after_A', 'pred_B', 'after_B', \n",
    "       'head_A', 'nsubj_A', 'dobj_A', 'pobj_A', 'poss_A', 'paral_A', 'ad_A', 'nonad_A', \n",
    "       'head_B', 'nsubj_B', 'dobj_B', 'pobj_B', 'poss_B', 'paral_B', 'ad_B', 'nonad_B', \n",
    "       'pos_sent_A', 'pos_sent_B', 'A-dist', 'B-dist']\n",
    "\n",
    "model = multiclass.OneVsRestClassifier(ensemble.RandomForestClassifier(n_jobs=-1))\n",
    "param_grid = dict(estimator__criterion=['entropy', 'gini'], estimator__max_depth=[10,11,12], \n",
    "                  estimator__n_estimators=[1000, 1500], estimator__min_samples_split=[6,7,8],\n",
    "                  estimator__oob_score=['True', 'False'])\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_log_loss', cv=3, n_jobs=-1)\n",
    "grid_result = grid.fit(train[col].fillna(-1), train[['A', 'B', 'NEITHER']])\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators 1000, max_depth 12, min_samples_split 8, criterion entropy.\n",
      "random state 1\n",
      "('log_loss', 0.6218139593636542)\n",
      "('accuracy', 0.6666666666666666)\n",
      "random state 2\n",
      "('log_loss', 0.6556505964226502)\n",
      "('accuracy', 0.6610549943883277)\n",
      "random state 3\n",
      "('log_loss', 0.6617122700016389)\n",
      "('accuracy', 0.6498316498316499)\n",
      "random state 4\n",
      "('log_loss', 0.659407664907144)\n",
      "('accuracy', 0.6610549943883277)\n",
      "random state 5\n",
      "('log_loss', 0.6199876857331559)\n",
      "('accuracy', 0.6734006734006734)\n",
      "('log_loss', 0.411771069308881)\n",
      "('accuracy', 0.8175)\n",
      "Average 0.643714435286\n",
      "Average 0.662401795735\n",
      "\n",
      "n_estimators 1500, max_depth 12, min_samples_split 8, criterion entropy.\n",
      "random state 1\n",
      "('log_loss', 0.6216759434721244)\n",
      "('accuracy', 0.6689113355780022)\n",
      "random state 2\n",
      "('log_loss', 0.6545199661111505)\n",
      "('accuracy', 0.6621773288439955)\n",
      "random state 3\n",
      "('log_loss', 0.6616853175470045)\n",
      "('accuracy', 0.6520763187429854)\n",
      "random state 4\n",
      "('log_loss', 0.6591533774784148)\n",
      "('accuracy', 0.6576879910213244)\n",
      "random state 5\n",
      "('log_loss', 0.6191512181062326)\n",
      "('accuracy', 0.6734006734006734)\n",
      "('log_loss', 0.41155031972090667)\n",
      "('accuracy', 0.816)\n",
      "Average 0.643237164543\n",
      "Average 0.662850729517\n",
      "\n",
      "n_estimators 1000, max_depth 11, min_samples_split 7, criterion entropy.\n",
      "random state 1\n",
      "('log_loss', 0.6224007722591612)\n",
      "('accuracy', 0.67003367003367)\n",
      "random state 2\n",
      "('log_loss', 0.654583510045599)\n",
      "('accuracy', 0.6610549943883277)\n",
      "random state 3\n",
      "('log_loss', 0.6607858510708158)\n",
      "('accuracy', 0.6475869809203143)\n",
      "random state 4\n",
      "('log_loss', 0.6611960354057478)\n",
      "('accuracy', 0.6520763187429854)\n",
      "random state 5\n",
      "('log_loss', 0.618770865673182)\n",
      "('accuracy', 0.6677890011223344)\n",
      "('log_loss', 0.429629895005074)\n",
      "('accuracy', 0.8035)\n",
      "Average 0.643547406891\n",
      "Average 0.659708193042\n",
      "\n",
      "n_estimators 1500, max_depth 10, min_samples_split 7, criterion entropy.\n",
      "random state 1\n",
      "('log_loss', 0.6486523834803188)\n",
      "('accuracy', 0.6520763187429854)\n",
      "random state 2\n",
      "('log_loss', 0.6738968205176097)\n",
      "('accuracy', 0.6352413019079686)\n",
      "random state 3\n",
      "('log_loss', 0.6758663873004521)\n",
      "('accuracy', 0.6408529741863075)\n",
      "random state 4\n",
      "('log_loss', 0.6751958819368377)\n",
      "('accuracy', 0.6251402918069585)\n",
      "random state 5\n",
      "('log_loss', 0.6440320817858263)\n",
      "('accuracy', 0.6565656565656566)\n",
      "('log_loss', 0.5463667510293343)\n",
      "('accuracy', 0.724)\n",
      "Average 0.663528711004\n",
      "Average 0.641975308642\n",
      "\n",
      "n_estimators 1500, max_depth 10, min_samples_split 7, criterion gini.\n",
      "random state 1\n",
      "('log_loss', 0.6492240380490334)\n",
      "('accuracy', 0.6554433221099888)\n",
      "random state 2\n",
      "('log_loss', 0.6737492313305233)\n",
      "('accuracy', 0.6352413019079686)\n",
      "random state 3\n",
      "('log_loss', 0.6766443665428785)\n",
      "('accuracy', 0.6442199775533108)\n",
      "random state 4\n",
      "('log_loss', 0.6755308456196244)\n",
      "('accuracy', 0.6251402918069585)\n",
      "random state 5\n",
      "('log_loss', 0.6449697695223282)\n",
      "('accuracy', 0.6576879910213244)\n",
      "('log_loss', 0.5441025179338783)\n",
      "('accuracy', 0.7315)\n",
      "Average 0.664023650213\n",
      "Average 0.64354657688\n",
      "\n"
     ]
    }
   ],
   "source": [
    "col = ['pronoun_type', 'pred_A', 'after_A', 'pred_B', 'after_B', \n",
    "       'head_A', 'nsubj_A', 'dobj_A', 'pobj_A', 'poss_A', 'paral_A', 'ad_A', 'nonad_A', \n",
    "       'head_B', 'nsubj_B', 'dobj_B', 'pobj_B', 'poss_B', 'paral_B', 'ad_B', 'nonad_B', \n",
    "       'pos_sent_A', 'pos_sent_B', 'A-dist', 'B-dist']\n",
    "\n",
    "et1 = ensemble.ExtraTreesClassifier(min_samples_split=7, criterion= 'entropy', max_depth=10, n_estimators=1500, random_state=22)\n",
    "et2 = ensemble.ExtraTreesClassifier(min_samples_split=7, max_depth=10, n_estimators=1500, random_state=22)\n",
    "\n",
    "rmf1 = ensemble.RandomForestClassifier(n_estimators=1000, max_depth=12, min_samples_split=8, \n",
    "                                       criterion='entropy', random_state=22)\n",
    "rmf2 = ensemble.RandomForestClassifier(n_estimators=1500, max_depth=12, min_samples_split=8,  \n",
    "                                       criterion='entropy', random_state=22)\n",
    "rmf3 = ensemble.RandomForestClassifier(n_estimators=1000, max_depth=11, min_samples_split=7, \n",
    "                                       oob_score=True, criterion='entropy', random_state=22)\n",
    "dict = {}\n",
    "# for ind, modeli in enumerate([rmf1, rmf2, rmf3, rmf4, rmf5]):\n",
    "for ind, modeli in enumerate([rmf1, rmf2, rmf3, et1, et2]):\n",
    "    dict[ind] = {}\n",
    "    dict[ind][\"log_loss\"]=[]\n",
    "    dict[ind][\"accuracy\"]=[]\n",
    "    print(\"n_estimators {}, max_depth {}, min_samples_split {}, criterion {}.\".format(\n",
    "        modeli.n_estimators, modeli.max_depth, modeli.min_samples_split, modeli.criterion))\n",
    "    model = multiclass.OneVsRestClassifier(modeli)\n",
    "    for rstate in [1, 2, 3, 4, 5]:\n",
    "        print(\"random state {}\".format(rstate))\n",
    "        x1, x2, y1, y2 = model_selection.train_test_split(train[col].fillna(-1), train[['A', 'B', 'NEITHER']], test_size=0.2, random_state=rstate)\n",
    "        model.fit(x1, y1)\n",
    "        logloss = metrics.log_loss(y2, model.predict_proba(x2))\n",
    "        acc = model.score(x2, y2)\n",
    "        print('log_loss', logloss)\n",
    "        print('accuracy', acc)\n",
    "        dict[ind][\"log_loss\"].append(logloss)\n",
    "        dict[ind][\"accuracy\"].append(acc)\n",
    "        \n",
    "    model.fit(train[col].fillna(-1), train[['A', 'B', 'NEITHER']])\n",
    "    results = model.predict_proba(test[col])\n",
    "    print('log_loss', metrics.log_loss(submition[['A', 'B', 'NEITHER']], results))\n",
    "    print('accuracy', model.score(test[col], submition[['A', 'B', 'NEITHER']]))\n",
    "        \n",
    "    print(\"Average {}\".format(sum(dict[ind][\"log_loss\"]) / float(5)))\n",
    "    print(\"Average {}\\n\".format(sum(dict[ind][\"accuracy\"]) / float(5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
